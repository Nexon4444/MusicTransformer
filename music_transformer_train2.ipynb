{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "music-transformer-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cd /content/drive/'My Drive'/MusicTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install progress\n",
    "!pip install pretty_midi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.7.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "!python preprocess.py midi_classical midi_processed\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(os.listdir())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import MusicTransformer\n",
    "from custom.layers import *\n",
    "from custom import callback\n",
    "from tensorflow.python import keras\n",
    "# import params as par\n",
    "import midi_processor.processor as sequence\n",
    "from tensorflow.python import enable_eager_execution\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "from data import Data\n",
    "import utils\n",
    "tf.executing_eagerly()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_r = 0.001 #@param {type:\"slider\", min:0, max:0.1, step:0.0001}\n",
    "batch_size = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
    "pickle_dir = \"processed/\" #@param {type:\"string\"}\n",
    "max_seq = 2048 #@param {type:\"slider\", min:1, max:3000, step:1}\n",
    "epochs = 41 #@param {type:\"slider\", min:1, max:10000, step:1}\n",
    "model_save_path = \"bin/models\" #@param {type:\"string\"}\n",
    "embedding_dim = 256 #@param {type:\"slider\", min:2, max:2048, step:1}\n",
    "\n",
    "event_dim = sequence.RANGE_NOTE_ON + sequence.RANGE_NOTE_OFF + sequence.RANGE_TIME_SHIFT + sequence.RANGE_VEL\n",
    "vocab_size = event_dim + 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = Data('dataset/processed/')\n",
    "opt = Adam(l_r)\n",
    "mt = MusicTransformer(\n",
    "    embedding_dim=embedding_dim, \n",
    "    vocab_size=vocab_size, \n",
    "    num_layer=3, \n",
    "    max_seq=max_seq,\n",
    "    debug=False)\n",
    "mt.compile(optimizer=opt, loss=callback.TransformerLoss())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = self.fit(prepared_data.dataset, prepared_data.dataset, epochs=epochs)\n",
    "        print(history.history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "    for e in range(epochs):\n",
    "        for b in range(len(dataset.files) // batch_size):\n",
    "            batch_x, batch_y = dataset.seq2seq_batch(batch_size, par.max_seq)\n",
    "            result_metrics = mt.train_on_batch(batch_x, batch_y)\n",
    "            if b % 1 == 0:\n",
    "              print('===========================================\\n')\n",
    "              print('Loss: {:6.6}, Accuracy: {:3.2}'.format(result_metrics[0], result_metrics[1]))\n",
    "              mt.save('mt-2048-h4-dim256.h5', )\n",
    "              \n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MusicTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python train.py --epochs=1 --pickle_dir=\"dataset/processed\" --save_path=\"bin/models\" --max_seq=2048  --batch_size=1 --l_r=0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fill_with_placeholder(prev_data: list, max_len: int, max_val: int=239):\n",
    "    placeholder = [max_val for _ in range(max_len - len(prev_data))]\n",
    "    return placeholder+prev_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(max_seq):\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# suppress warning/error messages in terminal\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# load in data from mnist dataset (60k training, 10k test)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape and convert to one-hot\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# split main training set into train/validation sets (6k out of 60k data points reserved for validation)\n",
    "x_validate = x_train[:6000, :]\n",
    "y_validate = y_train[:6000, :]\n",
    "x_train = x_train[6000:, :]\n",
    "y_train = y_train[6000:, :]\n",
    "\n",
    "'''\n",
    "Building layers for the feedforward NN:\n",
    "Hidden layers have 56, 96, 96, and 56 nodes, in that order.\n",
    "Takes in 784 values (pixel input) and outputs 10 values (predicted probability for each number, 0-9).\n",
    "'''\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(56,activation='relu',input_shape=(784,)))\n",
    "model.add(layers.Dense(96,activation='relu'))\n",
    "model.add(layers.Dense(96,activation='relu'))\n",
    "model.add(layers.Dense(56,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "\t\t\t  optimizer='adam',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "# training the NN\n",
    "epochs = 20\n",
    "history = model.fit(x_train,y_train,epochs=epochs,batch_size=512,verbose=2,validation_data=(x_validate,y_validate))\n",
    "print(\"Finished fitting.\")\n",
    "\n",
    "# plotting learning curves during training (on both training and validation data)\n",
    "epoch_labels = range(1, epochs+1)\n",
    "hist_dict = history.history\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.plot(epoch_labels, hist_dict[\"acc\"],'bo', label=\"Training\")\n",
    "plt.plot(epoch_labels, hist_dict[\"val_acc\"],'go', label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# evaluating final performance using test data\n",
    "print(\"Checking accuracy on test set...\")\n",
    "acc = model.evaluate(x_test,y_test,batch_size=512)\n",
    "print(\"\\nAccuracy on test set: \" + str(acc[1]))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}